{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gen_embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "laBA_P_lFoCb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "# from torch._C import *\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "import torch.nn.functional as F\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrbgxaVyFxij",
        "outputId": "b290c45f-b320-4a0a-f747-a4eafc6cb02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1v5eHy3GA3E"
      },
      "source": [
        "file = open('/content/drive/My Drive/BiGPatentSample.txt',mode='r')\n",
        " \n",
        "# read all lines at once\n",
        "my_data = file.read()\n",
        " \n",
        "# close the file\n",
        "file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLmo5p5NUf1x",
        "outputId": "d418996b-c80b-4ae7-923b-f446a6e7eadf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stop_file = open(\"/content/drive/My Drive/NLTK's list of english stopwords\",mode='r')\n",
        "stop_words = stop_file.read()\n",
        "stop_file.close()\n",
        "stop_words = stop_words.split('\\n')\n",
        "print(stop_words)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5e4zLm3Rfb-"
      },
      "source": [
        "my_data = my_data.split('}')\n",
        "\n",
        "x = \"\"\n",
        "for itm in my_data :\n",
        "  abst =  itm.split(\"\\\"abstract\\\":\",1)\n",
        "  if len(abst)!=1:\n",
        "    abst = abst[1].split(\"\\\"application_number\\\":\")[0]\n",
        "    # x.append(abst)\n",
        "    x = x + abst\n",
        "  full_txt = itm.split(\"\\\"description\\\":\")\n",
        "  if len(full_txt)!=1:\n",
        "    # x.append(full_txt[1])\n",
        "    x = x + full_txt[1]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CaIdYEsTjoa"
      },
      "source": [
        "def clean(text):\n",
        "  text = str(text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\'s',r'\\tis',text)\n",
        "  text = re.sub(r'\\'ll',r'\\twill',text)\n",
        "  text = re.sub(r'\\'m',r'\\tam',text)\n",
        "  text = re.sub(r'\\'re',r'\\tare',text)\n",
        "  text = re.sub(r'\\'d',r'\\twould',text)\n",
        "  text = re.sub(r'n\\'t',r'\\tnot',text)\n",
        "  # print(\"1***\",text)\n",
        "  for itm in stop_words:\n",
        "    text = re.sub(' '+itm +' ',' ',text)\n",
        "    text = re.sub('\"'+ itm + ' ',' ', text)\n",
        "  \n",
        "  # print(\"2***\", text)\n",
        "  text = re.sub('fig[0-9]+',' ',text)\n",
        "  text = re.sub('[^a-zA-Z0-9]',' ',text) \n",
        "  text = re.sub('\\w{1,}[0-9]+', ' ', text)\n",
        "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "  text = re.sub('^a$','', text)\n",
        "  return text"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2v4vh_sTk1c"
      },
      "source": [
        "common_texts = clean(x)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keTE_7y1Rd7r"
      },
      "source": [
        "# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "model1 = gensim.models.Word2Vec(common_texts, min_count = 1,   size = 300, window = 12) \n",
        "model1.save(\"word2vec.model\")"
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}